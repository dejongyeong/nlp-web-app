{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "@InProceedings{maas-EtAl:2011:ACL-HLT2011,<br/>\n",
    "  &ensp;&ensp;&ensp;author = {Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher},<br/>\n",
    "  &ensp;&ensp;&ensp;title = {Learning Word Vectors for Sentiment Analysis},<br/>\n",
    "  &ensp;&ensp;&ensp;booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},<br/>\n",
    "  &ensp;&ensp;&ensp;month = {June},<br/>\n",
    "  &ensp;&ensp;&ensp;year = {2011},<br/>\n",
    "  &ensp;&ensp;&ensp;address = {Portland, Oregon, USA},<br/>\n",
    "  &ensp;&ensp;&ensp;publisher = {Association for Computational Linguistics},<br/>\n",
    "  &ensp;&ensp;&ensp;pages = {142--150},<br/>\n",
    "  &ensp;&ensp;&ensp;url = {http://www.aclweb.org/anthology/P11-1015}<br/>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dejon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dejon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dejon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dejon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# common libraries\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import tabulate\n",
    "\n",
    "# natural language toolkit libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import sklearn.metrics as mtr\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# bidirectional encoder representations from transformers sentiment analysis\n",
    "# hugging face ai platforms\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "# files\n",
    "from contractions import CONTRACTION_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.7.0\n",
      "GPU: AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# check tensorflow version and is gpu available\n",
    "is_available = \"AVAILABLE\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\"\n",
    "print(f\"Version: {tf.__version__}\\nGPU: {is_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download IMDB dataset\n",
    "tfds.load(name='imdb_reviews', data_dir='[replace with your own data directory]', download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset or Build and Clean from Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_clean():\n",
    "    # tensorflow load train dataset\n",
    "    builder = tfds.core.builder_from_directory('D:\\\\Portfolio\\\\nlp-web-app\\\\model\\\\imdb_reviews\\\\plain_text\\\\1.0.0')\n",
    "\n",
    "    # as_supervised argument - set the structure of the dataset as input and label\n",
    "    dataset = builder.as_dataset(split=('train', 'test'), shuffle_files=True, as_supervised=True)      # 70% train 30% test\n",
    "    train, test = dataset\n",
    "    data = train.concatenate(test)\n",
    "    data = tfds.as_dataframe(ds=data, ds_info=builder.info)     # require jinja2\n",
    "    print(f\"Train + Test Size: {len(data)}\")\n",
    "\n",
    "    df_train, df_test = split_dataset(data)\n",
    "    return df_train, df_test\n",
    "\n",
    "def split_dataset(data):\n",
    "    # split data into 70:30\n",
    "    # random_state: ensure the splits generated are reproducible (persistant)\n",
    "    train_set, test_set = train_test_split(data, test_size=0.3, shuffle=True, random_state=42)\n",
    "    print(f\"Train: {len(train_set)}, Test: {len(test_set)}\")\n",
    "\n",
    "    # deep copy of dataframe\n",
    "    df_train = train_set.copy(deep=True)    # label 0 = negative; 1 = positive\n",
    "    df_test = test_set.copy(deep=True)\n",
    "\n",
    "    # remove trailing and leading whitespace and lowercase\n",
    "    df_train['text'] = [x.decode('utf-8').strip().lower() for x in df_train.text]\n",
    "    df_test['text'] = [x.decode('utf-8').strip().lower() for x in df_test.text]\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def save_train_test_dataset(df_train, df_test):\n",
    "    # output the dataframes from the preprocessing above into csv files\n",
    "    # so that in future we just have to load in the csv files.\n",
    "    df_train.to_csv('train.csv', index=False, encoding='utf-8')\n",
    "    df_test.to_csv('test.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://towardsdatascience.com/nlp-learning-series-part-1-text-preprocessing-methods-for-deep-learning-20085601684b\n",
    "# reference: https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string\n",
    "# things to consider: drop rows with empty text and spelling corrections\n",
    "def remove_html_tags(text):\n",
    "    if bool(re.search(r'<.*?>', text)):\n",
    "        text = re.sub(r'<.*?>', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# expand contractions, e.g., don't -> do not, purpose is to standardize our text\n",
    "def get_contractions(contraction_mapping):\n",
    "    contraction_regex = re.compile('(%s)' % '|'.join(contraction_mapping.keys()))\n",
    "    return contraction_mapping, contraction_regex\n",
    "\n",
    "contractions, contractions_pattern = get_contractions(CONTRACTION_MAP)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_pattern.sub(replace, text)\n",
    "\n",
    "\n",
    "def add_space_between_punctuations(text):\n",
    "    text = re.sub(r'([a-zA-Z])([,.!()])', r'\\1\\2 ', text)       # add space between punctuations and letters\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    stopword_list = [item for item in stopword_list if item not in ('no', 'not', 'nor', 'any', 'too')]  # useful information\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if not word in stopword_list] \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "def remove_punctuations(text, filters):\n",
    "    text = text.translate(str.maketrans('', '', filters))\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_multiple_whitespace(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# main function to clean text - ordering of function can be a factor for data cleaning\n",
    "def clean_text(text, remove_stopword=False, use_bert=False):\n",
    "    text = remove_html_tags(text)\n",
    "    text = add_space_between_punctuations(text)\n",
    "    text = replace_contractions(text)\n",
    "    \n",
    "    if not use_bert:        # allow text in bert (bidirectional encoder representations from transformers)\n",
    "        text = re.sub(r'\\+|\\d+', '', text)\n",
    "\n",
    "    if remove_stopword:\n",
    "        text = remove_stopwords(text)\n",
    "\n",
    "    # reference: https://github.com/hmohebbi/SentimentAnalysis/blob/master/main.ipynb\n",
    "    # save certain punctuations if using bert because bert embeddings was trained on wikipedia\n",
    "    filters = string.punctuation + \"\\t\\n\"\n",
    "    if use_bert:\n",
    "        text = re.sub(r'\\!+', '!', text)\n",
    "        text = re.sub(r'\\!+', '!', text)\n",
    "        filters = set(filters) - set(\"-'!?).;,/:(\")\n",
    "        filters = ''.join(filters)\n",
    "    text = remove_punctuations(text, filters)\n",
    "\n",
    "    if use_bert:        # remove empty brackets\n",
    "        text = re.sub(r'\\( *\\)', ' ', text)\n",
    "\n",
    "    text = remove_multiple_whitespace(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# part of speeh tagging and wordnet lemmatization\n",
    "# convert penn treebank tag to wordnet tag\n",
    "# reference: https://github.com/prateek22sri/Sentiment-analysis/blob/master/unigramSentiWordNet.py\n",
    "# reference: https://github.com/KT12/tag-lemmatize/blob/master/tag-lemmatize.py\n",
    "# reference: https://wordnet.princeton.edu/documentation/wnintro3wn\n",
    "# other techniques include stemming\n",
    "# stemming is not use in this context as it removes or stems the last few characters, often leading to incorrect spelling\n",
    "def convert_tag(penn_tag):\n",
    "    \"\"\"\n",
    "    Convert between PennTreebank to WordNet tags\n",
    "    \"\"\"\n",
    "    if penn_tag.startswith('N'):     # Noun\n",
    "        return wordnet.NOUN\n",
    "    elif penn_tag.startswith('V'):   # Verb\n",
    "        return wordnet.VERB\n",
    "    elif penn_tag.startswith('J'):   # Adjective\n",
    "        return wordnet.ADJ\n",
    "    elif penn_tag.startswith('S'):   # Adjective Satellite\n",
    "        return 's'\n",
    "    elif penn_tag.startswith('R'):   # Adverb\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None  # other parts of speech will be returned as none\n",
    "\n",
    "def pos_and_lemm(text):       # part-of-speech tagging and word lemmatization\n",
    "    elements = word_tokenize(text)      # tokenize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    sentence = nltk.pos_tag(elements)\n",
    "    words = []\n",
    "\n",
    "    # list of tuples [('token'), 'tag'), ('token2'), 'tag2'...]\n",
    "    for word, tag in sentence:\n",
    "        wn_tag = convert_tag(tag)\n",
    "        if wn_tag is None:\n",
    "            continue\n",
    "        words.append(lemmatizer.lemmatize(word, wn_tag))\n",
    "    \n",
    "    return ' '.join(words)      # O(n) time complexity, if use += it will be O(n^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_and_test(df_train, df_test, save_preprocessed_data=True):\n",
    "    # this section will take the longest time\n",
    "    # clean the entire train and test data and separate into new column\n",
    "    # contain stopwords\n",
    "    df_train['clean_sw'] = [clean_text(x, remove_stopword=False, use_bert=False) for x in df_train.text]\n",
    "    df_test['clean_sw'] = [clean_text(x, remove_stopword=False, use_bert=False) for x in df_test.text]\n",
    "\n",
    "    # no stopwords\n",
    "    df_train['clean_nsw'] = [clean_text(x, remove_stopword=True, use_bert=False) for x in df_train.text]\n",
    "    df_test['clean_nsw'] = [clean_text(x, remove_stopword=True, use_bert=False) for x in df_test.text]\n",
    "\n",
    "    # for bert deep learning\n",
    "    # reference: https://stackoverflow.com/questions/63633534/is-it-necessary-to-do-stopwords-removal-stemming-lemmatization-for-text-classif\n",
    "    # when using contextual model like bert, stopwords are kept to provide context information like negation words, e.g., not, nor\n",
    "    df_train['bert'] = [clean_text(x, remove_stopword=False, use_bert=True) for x in df_train.text]\n",
    "    df_test['bert'] = [clean_text(x, remove_stopword=False, use_bert=True) for x in df_test.text]\n",
    "\n",
    "    # normalize with part-of-speech tagging (each word)\n",
    "    # with stopwords\n",
    "    df_train['clean_sw_normalize'] = [pos_and_lemm(x) for x in df_train.clean_sw]\n",
    "    df_test['clean_sw_normalize'] = [pos_and_lemm(x) for x in df_test.clean_sw]\n",
    "\n",
    "    # without stopwords\n",
    "    df_train['clean_nsw_normalize'] = [pos_and_lemm(x) for x in df_train.clean_nsw]\n",
    "    df_test['clean_nsw_normalize'] = [pos_and_lemm(x) for x in df_test.clean_nsw]\n",
    "\n",
    "    if save_preprocessed_data:\n",
    "        save_train_test_dataset(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from CSV - Train Size: 35000 and Test Size: 15000\n"
     ]
    }
   ],
   "source": [
    "# load csv if containing train.csv and test.csv else build from tensorflow dataset\n",
    "train_filepath = \"./train.csv\"\n",
    "test_filepath = \"./test.csv\"\n",
    "if os.path.isfile(train_filepath) and os.path.isfile(test_filepath):      # change to your corresponding filepath\n",
    "    df_train = pd.read_csv(train_filepath)\n",
    "    df_test = pd.read_csv(test_filepath)\n",
    "    print(f\"Load from CSV - Train Size: {len(df_train)} and Test Size: {len(df_test)}\")\n",
    "else:\n",
    "    df_train, df_test = build_and_clean()\n",
    "    df_train, df_test = preprocess_train_and_test(df_train, df_test, save_preprocessed_data=True)\n",
    "    print(f\"Build from TF Dataset - Train Size: {len(df_train)} and Test Size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to Save Model and Output Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(models: list, filename: str):\n",
    "    joblib.dump(models, filename, compress=3)\n",
    "\n",
    "def print_metrics(accuracy, precision, recall, f1):\n",
    "    metrics_df = np.array([accuracy, precision, recall, f1])\n",
    "    metrics_df = pd.DataFrame([metrics_df], columns=['accuracy', 'precision', 'recall', 'f1'], index=['metrics'])\n",
    "    print('Performance Metrics:\\n')\n",
    "    print(tabulate.tabulate(metrics_df, headers='keys', tablefmt='github'))\n",
    "\n",
    "def plot_confusion_matrix(test_sentiment, pred, plot_title):       # plot receiver operating characteristics (need to understand this!!!)\n",
    "    cm = mtr.confusion_matrix(test_sentiment, pred)      # negative, positive\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    fig.colorbar(ax.matshow(cm))\n",
    "\n",
    "    # reference: https://vitalflux.com/python-draw-confusion-matrix-matplotlib/\n",
    "    for row in range(cm.shape[0]):      # put numbers onto matrix -- O(n^2): can this be improved\n",
    "        for col in range(cm.shape[1]):\n",
    "            ax.text(x=col, y=row, s=cm[row, col], va='center', ha='center')\n",
    "\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('true')\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes with and without Stop Words for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_feature, train_sentiment, test_feature, test_sentiment, output_model: bool, output_filename: str, tfidf_vectorizer):\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(train_feature, train_sentiment)\n",
    "    \n",
    "    #save model\n",
    "    if output_model:\n",
    "        save_model(models=[tfidf_vectorizer, mnb], filename=output_filename)   # save filename (should check for duplicates)\n",
    "\n",
    "    # predict\n",
    "    mnb_pred = mnb.predict(test_feature)\n",
    "    mnb_prob = mnb.predict_proba(test_feature)[:,1]     # for plotting receiver operating characteristic (roc) curve if needed\n",
    "\n",
    "    # model evaluation metrics\n",
    "    mnb_accuracy = np.round(mtr.accuracy_score(test_sentiment, mnb_pred), 3)\n",
    "    mnb_precision = np.round(mtr.precision_score(test_sentiment, mnb_pred, average=\"weighted\"), 3)\n",
    "    mnb_recall = np.round(mtr.recall_score(test_sentiment, mnb_pred), 3)\n",
    "    mnb_f1 = np.round(mtr.f1_score(test_sentiment, mnb_pred, average=\"weighted\"), 3)\n",
    "    return mnb_accuracy, mnb_precision, mnb_recall, mnb_f1, mnb_pred, mnb_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train With Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "\n",
      "|         |   accuracy |   precision |   recall |    f1 |\n",
      "|---------|------------|-------------|----------|-------|\n",
      "| metrics |      0.885 |       0.887 |    0.855 | 0.885 |\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ngram_range - a tuple of lower and upper boundary of range of n-values for different n-grams to be extracted\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), use_idf=True)\n",
    "train_feature = vectorizer.fit_transform(df_train['clean_sw_normalize'].ravel())     #  contiguous flattened array\n",
    "train_sentiment = df_train['label']\n",
    "test_feature = vectorizer.transform(df_test['clean_sw_normalize'].ravel())\n",
    "test_sentiment = df_test['label']\n",
    "\n",
    "mnb_accuracy, mnb_precision, mnb_recall, mnb_f1, mnb_pred, mnb_prob = train_model(train_feature=train_feature,\n",
    "                                                                                  train_sentiment=train_sentiment,\n",
    "                                                                                  test_feature=test_feature,\n",
    "                                                                                  test_sentiment=test_sentiment,\n",
    "                                                                                  output_model=True, \n",
    "                                                                                  output_filename='multinomialnb_with_stopwords.joblib',\n",
    "                                                                                  tfidf_vectorizer=vectorizer)\n",
    "\n",
    "print_metrics(mnb_accuracy, mnb_precision, mnb_recall, mnb_f1)\n",
    "plot_title = 'Confusion Matrix of ML - Multinomial NB with Stopwords\\n'\n",
    "plot_confusion_matrix(test_sentiment=test_sentiment, pred=mnb_pred, plot_title=plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- **Label \"0\"** - Negative Sentiment.\n",
    "- **Label \"1\"** - Positive Sentiment\n",
    "- Correctly predicted **6869** negative sentiments. **629** of the negative sentiments were predicted to be positive sentiments.\n",
    "- Correctly predicted **6411** positive sentiments. **1091** of the positive sentiments were predicted to be negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Without Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "\n",
      "|         |   accuracy |   precision |   recall |    f1 |\n",
      "|---------|------------|-------------|----------|-------|\n",
      "| metrics |      0.885 |       0.885 |    0.872 | 0.885 |\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ngram_range - a tuple of lower and upper boundary of range of n-values for different n-grams to be extracted\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), use_idf=True)\n",
    "train_feature = vectorizer.fit_transform(df_train['clean_nsw_normalize'].ravel())     #  contiguous flattened array\n",
    "train_sentiment = df_train['label']\n",
    "test_feature = vectorizer.transform(df_test['clean_nsw_normalize'].ravel())\n",
    "test_sentiment = df_test['label']\n",
    "\n",
    "mnb_accuracy, mnb_precision, mnb_recall, mnb_f1, mnb_pred, mnb_prob = train_model(train_feature=train_feature,\n",
    "                                                                                  train_sentiment=train_sentiment,\n",
    "                                                                                  test_feature=test_feature,\n",
    "                                                                                  test_sentiment=test_sentiment,\n",
    "                                                                                  output_model=True, \n",
    "                                                                                  output_filename='multinomialnb_no_stopwords.joblib', \n",
    "                                                                                  tfidf_vectorizer=vectorizer)\n",
    "\n",
    "print_metrics(mnb_accuracy, mnb_precision, mnb_recall, mnb_f1)\n",
    "plot_title = 'Confusion Matrix of ML - Multinomial NB without Stopwords\\n'\n",
    "plot_confusion_matrix(test_sentiment=test_sentiment, pred=mnb_pred, plot_title=plot_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- **Label \"0\"** - Negative Sentiment.\n",
    "- **Label \"1\"** - Positive Sentiment\n",
    "- Correctly predicted **6731** negative sentiments. **767** of the negative sentiments were predicted to be positive sentiments.\n",
    "- Correctly predicted **6543** positive sentiments. **959** of the positive sentiments were predicted to be negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "- Results showed that stop words, e.g, a, the, is, are, etc. can some affect on the overall performance metrics, specifically on the precision score and recall score.\n",
    "- It has a difference of 0.2% and 1.7% in the precision score and recall score, respectively, between training with stop words and without stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = joblib.load('./multinomialnb_with_stopwords.joblib')\n",
    "# vect = joblib.load('./multinomialnb_with_stopwords_vectorizer.joblib')\n",
    "\n",
    "# a = vect.transform(['today is a day!!!'])    # must be an array\n",
    "# xnew = xx.predict(a)\n",
    "# probability = xx.predict_proba(a)\n",
    "# print(xnew[0])\n",
    "# print(probability)\n",
    "# print(probability[:,xnew[0]])          # class 0 = 1st col, class 1 = 2nd col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT Approach for Sentiment Analysis\n",
    "\n",
    "Reference: [Orhan G. Yalçın](https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# pre-trained model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109482240 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only the require columns\n",
    "df_train_bert = df_train[['bert', 'label']].copy()\n",
    "df_test_bert = df_test[['bert', 'label']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences by converting train/test data into suitable objects for BERT model\n",
    "def convert_to_examples(train: pd.DataFrame, test: pd.DataFrame) -> tuple[InputExample, InputExample]:\n",
    "    train_examples = train.apply(lambda x: InputExample(guid=None, \n",
    "                                                        text_a=x['bert'].strip(), \n",
    "                                                        text_b=None, \n",
    "                                                        label=x['label']), axis=1)\n",
    "    \n",
    "    test_examples = test.apply(lambda x: InputExample(guid=None,\n",
    "                                                      text_a=x['bert'].strip(),\n",
    "                                                      text_b=None,\n",
    "                                                      label=x['label']), axis=1)\n",
    "\n",
    "    return train_examples, test_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples, test_examples = convert_to_examples(df_train_bert, df_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize input examples and create require input format with the tokenized objects for the model\n",
    "# increase max length if have higher specs\n",
    "def convert_to_tf(train_examples: list, tokenizer: BertTokenizer, max_length=64):\n",
    "    features = []       # to store input features\n",
    "    for example in train_examples:\n",
    "        input_dict = tokenizer.__call__(\n",
    "            example.text_a,\n",
    "            add_special_tokens=True,\n",
    "            padding='max_length',\n",
    "            max_length=max_length,      # will pad to the maximum input size of the model, i.e., 512 for Bert\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict['input_ids'], \n",
    "                                                     input_dict['token_type_ids'],\n",
    "                                                     input_dict['attention_mask'])\n",
    "        features.append(InputFeatures(input_ids=input_ids, \n",
    "                                      attention_mask=attention_mask, \n",
    "                                      token_type_ids=token_type_ids,\n",
    "                                      label=example.label))\n",
    "\n",
    "    def generate() :\n",
    "        for feature in features:\n",
    "            yield({\n",
    "                \"input_ids\": feature.input_ids,\n",
    "                \"attention_mask\": feature.attention_mask,\n",
    "                \"token_type_ids\": feature.token_type_ids,\n",
    "            }, feature.label)\n",
    "    \n",
    "    return tf.data.Dataset.from_generator(generate,\n",
    "                                          ({\"input_ids\": tf.int32, \n",
    "                                            \"attention_mask\": tf.int32, \n",
    "                                            \"token_type_ids\": tf.int32}, tf.int64),\n",
    "                                          (\n",
    "                                              {\n",
    "                                                  \"input_ids\": tf.TensorShape([None]),\n",
    "                                                  \"attention_mask\": tf.TensorShape([None]),\n",
    "                                                  \"token_type_ids\": tf.TensorShape([None]),\n",
    "                                              }, tf.TensorShape([]) \n",
    "                                          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare train and test dataset\n",
    "# increase batch size if have higher specs\n",
    "train_data = convert_to_tf(list(train_examples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(16).repeat(2)\n",
    "\n",
    "test_data = convert_to_tf(list(test_examples), tokenizer)\n",
    "test_data = test_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train bert and using Adam as optimizer, categorical cross entropy as loss, and sparse categorical as accuracy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4376/4376 [==============================] - 3110s 704ms/step - loss: 0.3053 - accuracy: 0.8625 - val_loss: 0.4348 - val_accuracy: 0.8326\n",
      "Epoch 2/5\n",
      "4376/4376 [==============================] - 3074s 702ms/step - loss: 0.0731 - accuracy: 0.9737 - val_loss: 0.6425 - val_accuracy: 0.8377\n",
      "Epoch 3/5\n",
      "4376/4376 [==============================] - 3055s 698ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.8713 - val_accuracy: 0.8433\n",
      "Epoch 4/5\n",
      "4376/4376 [==============================] - 3056s 698ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.7385 - val_accuracy: 0.8457\n",
      "Epoch 5/5\n",
      "4376/4376 [==============================] - 3060s 699ms/step - loss: 0.0201 - accuracy: 0.9929 - val_loss: 0.8024 - val_accuracy: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x224baf50220>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here can edit to save checkpoints\n",
    "filepath = '[replace with your own data directory]'\n",
    "callback = tf.keras.callback.ModelCheckpoint(filepath=filepath, \n",
    "                                             monitor='val_acc', \n",
    "                                             verbose=0, \n",
    "                                             save_best_only=True, \n",
    "                                             mode='auto')\n",
    "\n",
    "model.fit(train_data, epochs=5, validation_data=test_data, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save_pretrained('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "load_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "load_model.load_weights('./tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17809248, 0.8219076 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "text = \"Today is a good day, maybe!\"\n",
    "text_token = tokenizer(text, truncation=True, padding=True, return_tensors='tf')\n",
    "pred = load_model(text_token)\n",
    "pred_probs = tf.nn.softmax(pred[0], axis=1).numpy()\n",
    "pred_probs          # [negative, positive] prob.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label = tf.argmax(pred_probs, axis=1).numpy()\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of file"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5766725d235d92a3f587ad84880941c04bca390e8d595877301ef928828de224"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
