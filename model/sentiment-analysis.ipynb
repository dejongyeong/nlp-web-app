{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# deep learning libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.7.0\n",
      "GPU: AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "# check tensorflow version and is gpu available\n",
    "is_available = \"AVAILABLE\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\"\n",
    "print(f\"Version: {tf.__version__}\\nGPU: {is_available}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "\n",
    "@InProceedings{maas-EtAl:2011:ACL-HLT2011,<br/>\n",
    "  &ensp;&ensp;&ensp;author = {Maas, Andrew L. and Daly, Raymond E. and Pham, Peter T. and Huang, Dan and Ng, Andrew Y. and Potts, Christopher},<br/>\n",
    "  &ensp;&ensp;&ensp;title = {Learning Word Vectors for Sentiment Analysis},<br/>\n",
    "  &ensp;&ensp;&ensp;booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},<br/>\n",
    "  &ensp;&ensp;&ensp;month = {June},<br/>\n",
    "  &ensp;&ensp;&ensp;year = {2011},<br/>\n",
    "  &ensp;&ensp;&ensp;address = {Portland, Oregon, USA},<br/>\n",
    "  &ensp;&ensp;&ensp;publisher = {Association for Computational Linguistics},<br/>\n",
    "  &ensp;&ensp;&ensp;pages = {142--150},<br/>\n",
    "  &ensp;&ensp;&ensp;url = {http://www.aclweb.org/anthology/P11-1015}<br/>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to D:\\Portfolio\\nlp-web-app\\model\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Size...: 100%|██████████| 80/80 [06:03<00:00,  4.55s/ MiB]\n",
      "Dl Completed...: 100%|██████████| 1/1 [06:03<00:00, 363.95s/ url]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to D:\\Portfolio\\nlp-web-app\\model\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{Split('train'): <PrefetchDataset shapes: {label: (), text: ()}, types: {label: tf.int64, text: tf.string}>,\n",
       " Split('test'): <PrefetchDataset shapes: {label: (), text: ()}, types: {label: tf.int64, text: tf.string}>,\n",
       " Split('unsupervised'): <PrefetchDataset shapes: {label: (), text: ()}, types: {label: tf.int64, text: tf.string}>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download IMDB dataset\n",
    "tfds.load(name='imdb_reviews', data_dir='[replace with your own data directory]', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Strictly a routine, by-the-numbers western (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'I was one of those \"few Americans\" that grew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"How did Mike Hammer live - in a penthouse wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b'For a long time it seemed like all the good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'I watched this movie after seeing other comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  b'Strictly a routine, by-the-numbers western (...\n",
       "1      0  b'I was one of those \"few Americans\" that grew...\n",
       "2      0  b\"How did Mike Hammer live - in a penthouse wi...\n",
       "3      1  b'For a long time it seemed like all the good ...\n",
       "4      0  b'I watched this movie after seeing other comm..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow load train dataset\n",
    "builder = tfds.core.builder_from_directory('[replace with your own data directory]\\\\imdb_reviews\\\\plain_text\\\\1.0.0')\n",
    "builder.info.splits['train'].num_examples\n",
    "\n",
    "dataset = builder.as_dataset(split=('train[:80%]', 'train[80%:]', 'test'), shuffle_files=True)      # 80% train 20% test\n",
    "df = tfds.as_dataframe(ds=dataset)      # require jinja2\n",
    "df.head()       # label 0 = negative; 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5766725d235d92a3f587ad84880941c04bca390e8d595877301ef928828de224"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
